{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Predicting Treatment Abandonment with scikit learn\n",
    "By **Daniel Palacio** (github.com/palaciodaniel) - 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP FOUR - Improving model with GridSearch\n",
    "Considering the dataset involves a sensitive subject (mental health) it becomes mandatory to look for the best model, the one with the best score. And since we are dealing with a very small dataset, then we can use GridSearch, so that we can determine which hyperparameters are the most suitable for the case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV # This is the new one we are importing.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 0 to 99\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count  Dtype\n",
      "---  ------                     --------------  -----\n",
      " 0   Age                        100 non-null    int64\n",
      " 1   Sex_Male                   100 non-null    int64\n",
      " 2   Victimhood                 100 non-null    int64\n",
      " 3   Discipline_Low             100 non-null    int64\n",
      " 4   Discipline_Medium          100 non-null    int64\n",
      " 5   Discipline_High            100 non-null    int64\n",
      " 6   Introspection_Low          100 non-null    int64\n",
      " 7   Introspection_Medium       100 non-null    int64\n",
      " 8   Introspection_High         100 non-null    int64\n",
      " 9   Motivation_Low             100 non-null    int64\n",
      " 10  Motivation_Medium          100 non-null    int64\n",
      " 11  Motivation_High            100 non-null    int64\n",
      " 12  Neuroticism_Low            100 non-null    int64\n",
      " 13  Neuroticism_Medium         100 non-null    int64\n",
      " 14  Neuroticism_High           100 non-null    int64\n",
      " 15  Resourcefulness_Low        100 non-null    int64\n",
      " 16  Resourcefulness_Medium     100 non-null    int64\n",
      " 17  Resourcefulness_High       100 non-null    int64\n",
      " 18  Social Expectation_Low     100 non-null    int64\n",
      " 19  Social Expectation_Medium  100 non-null    int64\n",
      " 20  Social Expectation_High    100 non-null    int64\n",
      " 21  Finished                   100 non-null    int64\n",
      "dtypes: int64(22)\n",
      "memory usage: 18.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Loading prepared DataFrame (only numeric values)\n",
    "\n",
    "df = pd.read_csv(\"df_prepared.csv\", header = 0, index_col = 0)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67  1  0  0  1  0  0  0  1  0  1  0  0  1  0  1  0  0  0  1  0]\n",
      " [35  0  0  0  1  0  1  0  0  0  0  1  1  0  0  1  0  0  0  1  0]\n",
      " [25  0  0  0  0  1  1  0  0  1  0  0  1  0  0  1  0  0  0  1  0]\n",
      " [48  0  0  0  0  1  0  1  0  0  0  1  1  0  0  0  0  1  1  0  0]\n",
      " [48  1  1  0  1  0  0  1  0  0  1  0  1  0  0  1  0  0  0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns\n",
    "\n",
    "X = df.iloc[:,:-1].to_numpy()\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Target column\n",
    "\n",
    "y = df.iloc[:, -1].to_numpy()\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (80, 21) <class 'numpy.ndarray'>\n",
      "X_test: (20, 21) <class 'numpy.ndarray'>\n",
      "y_train: (80,) <class 'numpy.ndarray'>\n",
      "y_test: (20,) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Dividing between training and test subsets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state = 24)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, type(y_test))\n",
    "print(\"X_test:\", X_test.shape, type(y_test))\n",
    "print(\"y_train:\", y_train.shape, type(y_test))\n",
    "print(\"y_test:\", y_test.shape, type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point there was not a big difference with Step 3, but now we are finally applying GridSearch...\n",
    "\n",
    "### Model application\n",
    "\n",
    "**IMPORTANT NOTE:** Logistic Regression has more parameters than the ones selected here; however, given that GridSearch looks for all possible combinations, in this case some of them weren't compatible, therefore it was pointless to spend processing time only to output a long list of warnings, and that is the main reason why some of them were ruled out.\n",
    "\n",
    "Also, scikit learn's __[documentation for Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)__ specifically recommends the solver 'liblinear' for small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(random_state=24),\n",
       "             param_grid={'C': [0.01, 0.1, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75,\n",
       "                               2.0, 2.5, 5, 10],\n",
       "                         'penalty': ['l1', 'l2'], 'solver': ['liblinear']})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating and fitting a Logistic Regression model with GridSearch\n",
    "\n",
    "log_reg = LogisticRegression(random_state = 24)\n",
    "\n",
    "params = {\n",
    "        \"penalty\": [\"l1\", \"l2\"], \n",
    "        \"C\": [0.01, 0.1, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 5, 10], \n",
    "        \"solver\": [\"liblinear\"]\n",
    "         }\n",
    "\n",
    "grid_search = GridSearchCV(log_reg, param_grid = params)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: (20,) [1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 0 1 1]\n",
      "y_test: (20,) [1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Making predictions, now with Grid Search\n",
    "\n",
    "y_pred = grid_search.predict(X_test_scaled)\n",
    "print(\"y_pred:\", y_pred.shape, y_pred)\n",
    "print(\"y_test:\", y_test.shape, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  3]\n",
      " [ 3 10]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 10\n",
      "True Negatives: 4\n",
      "False Positives: 3\n",
      "False Negatives: 3\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch revealed that the best parameters were the following:\n",
      " {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "The new (and improved) scores are the following:\n",
      "Accuracy: 0.7\n",
      "Precision 0.77\n",
      "Recall: 0.77\n"
     ]
    }
   ],
   "source": [
    "# The best parameters\n",
    "\n",
    "print(\"GridSearch revealed that the best parameters were the following:\\n\", grid_search.best_params_)\n",
    "\n",
    "# New accuracy, precision and recall scores\n",
    "\n",
    "print(\"\\nThe new (and improved) scores are the following:\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test,y_pred), 2))\n",
    "print(\"Precision\", round(precision_score(y_test,y_pred), 2))\n",
    "print(\"Recall:\", round(recall_score(y_test,y_pred), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Using GridSearch definitely improved the scores; it is far from being a robust model, of course, and even more considering it is about a delicate subject, as it was already expressed before. However, if we think that we used a dataset containing only 100 observations, it is already a promising start. \n",
    "\n",
    "Obviously, if we were going to continue improving the model, we would need to add much more observations. Thousands of them, to be precise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
