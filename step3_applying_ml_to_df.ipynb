{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Predicting Treatment Abandonment with scikit learn\n",
    "By **Daniel Palacio** (github.com/palaciodaniel) - 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP THREE - Applying Machine Learning\n",
    "Having a fully numeric DataFrame, now we are ready to apply a Machine Learning model on it. Considering the target column \"Finished\" is binary (whether the patient finished the treatment or not), we will be using a Logistic Regression model.\n",
    "\n",
    "This model will require us to scale the data, to avoid one column having more prevalence than the others.\n",
    "\n",
    "Several metrics were used to assess the quality of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 100 entries, 0 to 99\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count  Dtype\n",
      "---  ------                     --------------  -----\n",
      " 0   Age                        100 non-null    int64\n",
      " 1   Sex_Male                   100 non-null    int64\n",
      " 2   Victimhood                 100 non-null    int64\n",
      " 3   Discipline_Low             100 non-null    int64\n",
      " 4   Discipline_Medium          100 non-null    int64\n",
      " 5   Discipline_High            100 non-null    int64\n",
      " 6   Introspection_Low          100 non-null    int64\n",
      " 7   Introspection_Medium       100 non-null    int64\n",
      " 8   Introspection_High         100 non-null    int64\n",
      " 9   Motivation_Low             100 non-null    int64\n",
      " 10  Motivation_Medium          100 non-null    int64\n",
      " 11  Motivation_High            100 non-null    int64\n",
      " 12  Neuroticism_Low            100 non-null    int64\n",
      " 13  Neuroticism_Medium         100 non-null    int64\n",
      " 14  Neuroticism_High           100 non-null    int64\n",
      " 15  Resourcefulness_Low        100 non-null    int64\n",
      " 16  Resourcefulness_Medium     100 non-null    int64\n",
      " 17  Resourcefulness_High       100 non-null    int64\n",
      " 18  Social Expectation_Low     100 non-null    int64\n",
      " 19  Social Expectation_Medium  100 non-null    int64\n",
      " 20  Social Expectation_High    100 non-null    int64\n",
      " 21  Finished                   100 non-null    int64\n",
      "dtypes: int64(22)\n",
      "memory usage: 18.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Loading prepared DataFrame (only numeric values)\n",
    "\n",
    "df = pd.read_csv(\"df_prepared.csv\", header = 0, index_col = 0)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67  1  0  0  1  0  0  0  1  0  1  0  0  1  0  1  0  0  0  1  0]\n",
      " [35  0  0  0  1  0  1  0  0  0  0  1  1  0  0  1  0  0  0  1  0]\n",
      " [25  0  0  0  0  1  1  0  0  1  0  0  1  0  0  1  0  0  0  1  0]\n",
      " [48  0  0  0  0  1  0  1  0  0  0  1  1  0  0  0  0  1  1  0  0]\n",
      " [48  1  1  0  1  0  0  1  0  0  1  0  1  0  0  1  0  0  0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns\n",
    "\n",
    "X = df.iloc[:,:-1].to_numpy()\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Target column\n",
    "\n",
    "y = df.iloc[:, -1].to_numpy()\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (80, 21) <class 'numpy.ndarray'>\n",
      "X_test: (20, 21) <class 'numpy.ndarray'>\n",
      "y_train: (80,) <class 'numpy.ndarray'>\n",
      "y_test: (20,) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Dividing between training and test subsets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state = 24)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, type(y_test))\n",
    "print(\"X_test:\", X_test.shape, type(y_test))\n",
    "print(\"y_train:\", y_train.shape, type(y_test))\n",
    "print(\"y_test:\", y_test.shape, type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=24, solver='liblinear')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating and fitting a Logistic Regression model\n",
    "\n",
    "log_reg = LogisticRegression(solver= \"liblinear\", random_state = 24)\n",
    "\n",
    "log_reg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: (20,) [1 0 1 0 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 1]\n",
      "y_test: (20,) [1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Making predictions with the Logistic Regression model\n",
    "\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "print(\"y_pred:\", y_pred.shape, y_pred)\n",
    "print(\"y_test:\", y_test.shape, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.65\n",
      "Precision 0.8\n",
      "Recall: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Accuracy, recall and precision scores\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test,y_pred), 2))\n",
    "print(\"Precision\", round(precision_score(y_test,y_pred), 2))\n",
    "print(\"Recall:\", round(recall_score(y_test,y_pred), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 2]\n",
      " [5 8]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 8\n",
      "True Negatives: 5\n",
      "False Positives: 2\n",
      "False Negatives: 5\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy Scores: [0.85 0.8  0.75 0.6  0.6 ]\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(log_reg, X, y, cv=5)\n",
    "print(\"Cross Validation Accuracy Scores:\", scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
